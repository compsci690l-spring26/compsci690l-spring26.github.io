# Assignment 2
ðŸ“ [Starter code](/pages/assignments/lib/assignment2.zip)

## Table of contents
- [Setup](#setup)
- [Goals](#goals)
- [Q1: Neural Network (35 points)](#q1-neural-network-35-points)
- [Q2: Decision Tree (35 points)](#q2-decision-tree-35-points)
- [Q3: Naive Bayes (30 points)](#q3-naive-bayes-35-points)
- [Q4: Random Forest (extra 10 points)](#q4-random-forest-bonus-10-points)
- [Submitting your work](#submitting-your-work)


### [Setup](#setup)

Please familiarize yourself with the [recommended workflow](/pages/notes/doc/setup-instructions.html) before starting the assignment. 

The assignment would be using Python = 3.10

Make sure you install all the requirements with the command below in your terminal

```bash
pip install -r requirements.txt
```

**Note**. Ensure you are periodically saving your notebook (`File -> Save`) so that you don't lose your progress if you step away from the assignment and the Colab VM disconnects.

Once you have completed all Colab notebooks **except `collect_submission.ipynb`**, proceed to the [submission instructions](#submitting-your-work).

#### Colab

If using colab, make a new folder, (ex. `cs589`) in Google Drive and upload everything into the `assignment2` folder. Then, you right-click on any `.ipynb` file and click "Open with" â†’ "Google Colaboratory".

#### Running locally

If you're planning to run the code locally, make sure you downloaded this [VSCode extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter). 

### [Goals](#goals)

In **Q1** and **Q2**, you will be working with a dataset that tracks different features in their interaction with social media (screen time, number of likes, comments, etc.). Your task is to build a classifier that predict the people's well-being from those features. Your tasks will be:
- Preprocess the data (Cleaning, encoding, handling null values)
- Implement a 2-layer fully-connected **neural network** using 3 different activation functions: sigmoid, tanh, ReLU.
- Implement a **decision tree** using information gain.

In **Q3**, you will be implementing a **Naive Bayes classifier** and applying them on the Iris dataset, where you are given different features of an iris (petal length, petal width, etc.) to predict which type of iris it is (Setosa, Versicolour, Virginica).

In **Q4**, which is an extra-credit problem, you will be implementing a **Random Forest classifier** and applying it on the `cifar-10` dataset, which you might remember from assignment 1. You can use the classifier directly from `sklearn` and don't have to build it from scratch, but this may require a lot of tuning and adjustments.

### [Q1: Neural Network (35 points)](#q1-neural-network-35-points)

The Notebook **nn.ipynb** will walk you through the process of preprocessing and implementing the neural network. There will be visualizations as well.

### [Q2: Decision Tree (35 points)](#q2-decision-tree-35-points)

The Notebook **decision_tree.ipynb** will walk you through implementing a decision tree. There will be visualizations as well.

### [Q3: Naive Bayes (30 points)](#q3-naive-bayes-35-points)

The Notebook **naive_bayes.ipynb** will walk you through implementing the Naive Bayes Classifier from scratch.

### [Q4: Random Forest (bonus 10 points)](#q4-random-forest-bonus-10-points)

The Notebook **random_forest.ipynb** will show you the hyperparameters you need to tune. You might need to read `sklearn` documentation to understand better how the function work!

### [Submitting your work](#submitting-your-work)

**Important**. Please make sure that the submitted notebooks have been run and the cell outputs are visible.

1. Select every files in the `assignment2` folder and compress them into a zip file. Your zip file's contents should have the following structure:

```
â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”œâ”€â”€ decision_tree.ipynb
â”œâ”€â”€ naive_bayes.ipynb
â”œâ”€â”€ nn.ipynb
â”œâ”€â”€ random_forest.ipynb
â””â”€â”€ requirements.txt
```

2. Convert all notebooks (`.ipynb` files) into a single PDF file. In colab this can be done by selecting `File -> Print -> Print to PDF`. After that, merge them into one PDF to submit to Gradescope. I recommend using this [website](https://tools.pdf24.org/en/merge-pdf) for merging but you can use any tool you like. Submit the merged PDF file to Gradescope and assign each page to their corresponding question. You might lose points if there are missing pages assigned to the question so make sure you assign the pages correctly.

If you have any question, please feel free to message us on Piazza. Thanks for your time!